{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeoCities-seedlist-search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drjwbaker/geocities/blob/master/GeoCities_seedlist_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpl9oZDOHzyg"
      },
      "source": [
        "**This notebook will enable you to run a search on all the URLs for GeoCities pages archived by the Internet Archive. You won't have to write any code, just lightly edit the search.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3lW8l40VSIc"
      },
      "source": [
        "*Written for University of Sussex students by [James Baker](https://profiles.sussex.ac.uk/p371022-james-baker). If you have any problems, **contact me**. Please do not struggle in silence! If you have an improvement to suggest, also **contact me**.*\n",
        "\n",
        "*Forgive the typos :)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6gf5OflGYzp"
      },
      "source": [
        "1. Go to https://drive.google.com/file/d/1N0BtOlsq4V9U6lO5rdwwc2r_3Se9RbdH/view?usp=sharing or https://archive.org/details/webcrawl-geocities-seedlist to download the GeoCities Seedlist. This is a list of 38 URLs that were published on the now defunct web hosting service GeoCities between 1994 and 2009 (but most between 1995 and 2003, when it was most popular). For more on GeoCities see the work of Ian Milligan, e.g. https://uwspace.uwaterloo.ca/handle/10012/11650 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQoayyJsHYl7"
      },
      "source": [
        "2. Upload the Seedlist to your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7aKUpr-HdZI"
      },
      "source": [
        "3. Copy this Colab notebook to your Google Drive. To do this in the menu above hit 'File', then 'Save a Copy in Drive'. This will give you a copy you can edit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QziB5iHVINQW"
      },
      "source": [
        "4. In the code block below, hover to the left of `from` until a play button appears. Click play. This is how you run a code block. The code block will connect you Google Drive to this notebook.\n",
        "\n",
        "- Two things will appear: a link and a box asking for an authorisation code. Hit the link (it will open in a new tab), accept all the things that come up, copy the authorisation code, paste it into the box below, and hit enter.\n",
        "- If it worked, you'll see the output `Mounted at /content/drive` (or similar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbyt1j_VHOYI",
        "outputId": "0903f6bc-32ba-4339-e3ab-1283d0cb0c60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY2teoLvJR5i"
      },
      "source": [
        "5. Next we need to tell the notebook where the seedlist is on your Google Drive. Presuming you uploaded the seedlist to your Google Drive without putting in a particular folder, running the code block below will work. If you put it in a particular folder, put that after `MyDrive` (e.g. `/content/drive/MyDrive/my-dissertation-folder/ALL-GEO-SEEDS-20090730.txt`). When you are ready hit run below. Note there is no 'success' output, there is only an output if something goes wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khFj80lPHU2d"
      },
      "source": [
        "file_name = \"/content/drive/MyDrive/ALL-GEO-SEEDS-20090730.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v2EU5ILKjY-"
      },
      "source": [
        "6. Now for the fun it (and the hard bit!). The code block below searches all the URLs in the seedlist (to repeat, only the URLs not their contents). You can ignore every line below, apart from those that start `if` or `#if`.\n",
        "\n",
        "- first, run the code block. Note a few things: a) the output window gradually populates and finishes with 4 results, b) it takes a while to process, c) you can copy/paste results from the output window, d) all the results contain the exact string of characters `-rave` and either `uk` or `UK`, e) none of the search terms (e.g. `grrl` from the other lines are in the output, this is because of the `#` character that when placed at the start of a line instructs the computer to ignore that line.\n",
        "- second, look at each of the lines that start `if` or `#if`. They are examples of possible types of search. All are case-sensitive.\n",
        "  - `if re.search(r\"grrrl\", line):` will return URLs that contain the string `grrrl` in the list of URLs.\n",
        "  - `if re.search(r\"[Gg]rrrl\", line):` will return URLs that contain the strings `Grrrl` and `grrrl`.\n",
        "  - `if re.search(r\"grrrl\", line) and re.search(r\"riot\", line):` will return URLs that contain the strings `grrrl` or `riot`.\n",
        "  - `re.search(r\"-rave\", line) and re.search(r\"uk|UK\", line):` will return URLs that contain the strings `-rave` and either `uk` or `UK`.\n",
        "- third, create a new line for a new search.\n",
        "  - To do this first copy the line `re.search(r\"-rave\", line) and re.search(r\"uk|UK\", line):`.\n",
        "  - Next paste it between the line you've copied and `print(line, end=\"\")`. Make sure the indentation is the same (use tab to do this).\n",
        "  - Next add a `#` to the start of the line you've copied.\n",
        "  - Finally, edit the new line to `if re.search(r\"raver\", line) and re.search(r\"dance\", line):` and hit play.\n",
        "    - Note that you lose your output from the previous search, so always keep a copy of the results you want to use later.\n",
        "    - Note that because we are looking for the exact string `traver` we will get unwanted results: e.g. URLs with the string `traverse`. This is particularly true if we search the string `rave` which will return lots of results for URLs that contain the string `travel`. That is, this method can get you from 38m URLs to many fewer, but isn't perfect.\n",
        "- fourth, skip below the search code block for some notes on how to use the results.\n",
        "\n",
        "\n",
        "If you want to know more about the code below, it is written in Python, introductory lessons on which can be found at the [*Programming Historian*](https://programminghistorian.org/en/lessons/?topic=python&sortType=difficulty&sortOrder=asc). The searches use Regular Expression syntax, which is a simple search logic that almost all programmes use (e.g. Word), and is why the code `uk|UK` looks for either `uk` or `UK` in the URLs. There is a great tutorial on Regular Expressions at [*Library Carpentry*](https://librarycarpentry.org/lc-data-intro/01-regular-expressions/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF3RjkrtHx7A",
        "outputId": "f55ddd46-30f5-490c-e0a0-ebab9a479598"
      },
      "source": [
        "searchfile = open(file_name, \"r\", encoding=\"ISO-8859-1\")\n",
        "import re\n",
        "for line in searchfile:\n",
        "    #if re.search(r\"grrrl\", line):\n",
        "    #if re.search(r\"[Gg]rrrl\", line):\n",
        "    #if re.search(r\"grrrl\", line) or re.search(r\"riot\", line):\n",
        "    if re.search(r\"-rave\", line) and re.search(r\"uk|UK\", line):\n",
        "        print(line, end=\"\")\n",
        "searchfile.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "geocities.com/BeulahValenzuela17/central-co-uk-raver.html\n",
            "geocities.com/angelstrickland999/uk-raver.html\n",
            "geocities.com/korydawson68/the-rave-milwaukee-wi.html\n",
            "uk.geocities.com/pictures759gay/teen-titans-raven-and-beast-boy.htm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYfw-IRYTbqf"
      },
      "source": [
        "7. A few notes on using and interpreting the results:\n",
        "\n",
        "- enter the URLs you want to investigate at [web.archive.org](https://web.archive.org/) to read the pages. Not all URLs will work properly, but most will.\n",
        "- when a page was made can be hard to confirm. [web.archive.org](https://web.archive.org/) will tell you the date of last capture (that is, when the page was last snapped) but as many of these pages would have been dormant for a long time, they may be much older than the capture date. Clicking around the site (where pages work!) will usually provide some answers or a best guess.\n",
        "- some pages, however, will have multiple captures and these are great as they show the evolution of a GeoCities site.\n",
        "- the identity of the person who made the page and where they were based can be hard to interpret, which is which I used the search string `uk|UK` in one search.\n",
        "- going back to Milligan, be mindful that many of these pages were written during the early web, when search engines were bot powerful. It may seem weird to us today, but for GeoCities 'homesteaders' (as they were known) it was reasonable to assume - especially for those writing in the late-90s - that their page could only be found by browsing to it or by giving someone the URL. Which means there is a lot of very personal/private material on there. I've written about this and the ethics of using GeoCities if you'd like to know more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXKt7yZJezxh"
      },
      "source": [
        "This project is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/) (exceptions: logos and marked images). Project code is licensed under a [GNU General Public License v3.0](https://github.com/CuratorialVoice/code/blob/master/LICENSE). Terms of use for the [GeoCities seedlist](https://archive.org/details/webcrawl-geocities-seedlist) are available to [archive.org](https://archive.org/details/webcrawl-geocities-seedlist)."
      ]
    }
  ]
}